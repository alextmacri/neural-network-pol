{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5e90264-9303-478d-ae71-d9c6772244d5",
   "metadata": {},
   "source": [
    "# The Neural Network Structure and its Formulas\n",
    "these are the same as the first part of the presentation. The main things to focus on here are these 3 functions:\n",
    "\n",
    "1. sigmoid_activation_function\n",
    "\n",
    "![alt text](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fspiyer99.github.io%2Fimages%2Fpytorch_recommendation%2Fsigmoid1.png&f=1&nofb=1)\n",
    "\n",
    "2. forward_propagation\n",
    "\n",
    "![alt text](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fs3-ap-southeast-1.amazonaws.com%2Fkipalog.com%2F2abl6qud09_image.png&f=1&nofb=1)\n",
    "![alt text](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fcdn-images-1.medium.com%2Fmax%2F1600%2F1*tp73P0isrrfpj8RG-5aH6w.png&f=1&nofb=1)\n",
    "\n",
    "3. back_propagation\n",
    "\n",
    "![alt text](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fpantelis.github.io%2Fcs634%2Fdocs%2Fcommon%2Flectures%2Fdnn%2Fbackprop-intro%2Fimages%2Fbackprop-template.png&f=1&nofb=1)\n",
    "![alt text](https://external-content.duckduckgo.com/iu/?u=http%3A%2F%2Fwww.adeveloperdiary.com%2Fwp-content%2Fuploads%2F2019%2F04%2FUnderstand-and-Implement-the-Backpropagation-Algorithm-From-Scratch-In-Python-adeveloperdiary.com-4.jpg&f=1&nofb=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4111526e-008c-495f-ba2d-04c6b3a41b88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, *layers_sizes, name='Neural Network'):\n",
    "        self.layers = [np.zeros((size, 1)) for size in layers_sizes]\n",
    "        self.weights = [self.weight_init(layers_sizes[i+1], layers_sizes[i]) for i in range(len(layers_sizes)-1)]\n",
    "        self.biases = [np.zeros((size, 1)) for size in layers_sizes[1:]]\n",
    "        self.NAME = name\n",
    "        \n",
    "    def __repr__(self):\n",
    "        representation = 'network:\\n'\n",
    "        for layer in self.layers:\n",
    "            representation += str(layer.shape[0]) + ' -> '\n",
    "        representation = representation[:-4] + '\\n\\n'\n",
    "        \n",
    "        representation += '\\n\\nweights:\\n'\n",
    "        for weight_layer in self.weights:\n",
    "            representation += str(weight_layer) + '\\n\\n'\n",
    "            \n",
    "        representation += '\\n\\nbiases:\\n'\n",
    "        for bias_layer in self.biases:\n",
    "            representation += str(bias_layer) + '\\n\\n'\n",
    "            \n",
    "        return representation[:-2]\n",
    "    \n",
    "    def weight_init(self, y, x):\n",
    "        return np.random.uniform(-0.5, 0.5, (y, x))\n",
    "    \n",
    "    def sigmoid_activation_function(self, layer):\n",
    "        return 1 / (1 + np.exp(layer))\n",
    "    \n",
    "    def forward_propagation(self, input_layer):\n",
    "        self.layers[0] = input_layer\n",
    "        for i in range(1, len(self.layers)):\n",
    "            self.layers[i] = self.biases[i-1] + self.weights[i-1] @ self.layers[i-1]\n",
    "            self.layers[i] = self.sigmoid_activation_function(-self.layers[i])\n",
    "        return self.layers[-1]\n",
    "    \n",
    "    def back_propagation(self, output, label, alpha):\n",
    "        for i in range(-1, -(len(self.weights)+1), -1):\n",
    "            if i == -1:\n",
    "                delta = output - label\n",
    "            else:\n",
    "                delta = self.weights[i+1].T @ delta * (self.layers[i] * (1 - self.layers[i]))\n",
    "            self.weights[i] += -alpha * delta @ self.layers[i-1].T\n",
    "            self.biases[i] += -alpha * delta\n",
    "    \n",
    "    def learn(self, training_data, training_labels, epochs, alpha):\n",
    "        print(f'Starting to train {self.NAME}')\n",
    "        total = len(training_data)\n",
    "        for epoch in range(epochs):\n",
    "            num_correct = 0\n",
    "            for data, label in zip(training_data, training_labels):\n",
    "                data.shape = (data.shape[0], 1)\n",
    "                label.shape = (label.shape[0], 1)\n",
    "                \n",
    "                output = self.forward_propagation(data)\n",
    "                self.back_propagation(output, label, alpha)\n",
    "                \n",
    "                num_correct += int(np.argmax(output) == np.argmax(label))\n",
    "            \n",
    "            print(f'epoch {epoch+1}: {num_correct} out of {total} correct')\n",
    "        print(f'Done training {self.NAME}!')\n",
    "        \n",
    "    def test_set(self, test_data, test_labels):\n",
    "        num_correct = 0\n",
    "        for data, label in zip(test_data, test_labels):\n",
    "            data.shape = (data.shape[0], 1)\n",
    "            label.shape = (label.shape[0], 1)\n",
    "            \n",
    "            output = self.forward_propagation(data)\n",
    "            num_correct += int(np.argmax(output) == np.argmax(label))\n",
    "            \n",
    "        print('{}\\'s score: {:.2f}%'.format(self.NAME, num_correct/len(test_data)*100))\n",
    "        \n",
    "    def test_single(self, data, label):\n",
    "        print(f'guess: {self.forward_propagation(data).argmax()}\\nanswer: {label.argmax()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c403c666-eda7-44ef-8ad9-1774dd456d82",
   "metadata": {},
   "source": [
    "# Loading and Formatting the Handwritten Number Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5c6fabd-b85e-4b81-8cbb-f70f97e7c11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with np.load(f'data/mnist.npz') as f:\n",
    "    training_images = f['x_train'].astype('float32') / 255    # loading and regularizing\n",
    "    new_y, new_x = training_images.shape[0], training_images.shape[1] * training_images.shape[2]\n",
    "    training_images = np.reshape(training_images, (new_y, new_x))    # making each 2D image array into a 1D array\n",
    "    \n",
    "    training_labels = f['y_train']\n",
    "    training_labels = np.eye(10)[training_labels]    # shortcut to one hot encoding the labels\n",
    "    \n",
    "    test_images = f['x_test'].astype('float32') / 255    # repeating the previous steps for the test data\n",
    "    new_y, new_x = test_images.shape[0], test_images.shape[1] * test_images.shape[2]\n",
    "    test_images = np.reshape(test_images, (new_y, new_x))\n",
    "    \n",
    "    test_labels = f['y_test']\n",
    "    test_labels = np.eye(10)[test_labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeda952-743a-41cf-bf86-32bcc8ad53cf",
   "metadata": {},
   "source": [
    "# Instantiating and Training a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7efede7f-6b20-4e07-8328-3e7bf0f0ce87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train Neural Network\n",
      "epoch 1: 51602 out of 60000 correct\n",
      "epoch 2: 55259 out of 60000 correct\n",
      "epoch 3: 55854 out of 60000 correct\n",
      "Done training Neural Network!\n"
     ]
    }
   ],
   "source": [
    "NN = NeuralNetwork(784, 20, 10)\n",
    "# DNN = NeuralNetwork(784, 100, 20, 10, name='Deep Neural Network')\n",
    "# HNN = NeuralNetwork(784, 200, 100, 20, 10, name='Huge Neural Network')\n",
    "# GNN = NeuralNetwork(784, 300, 200, 100, 20, 10, name='Gigantic Neural Network')\n",
    "\n",
    "NN.learn(training_images, training_labels, 3, 0.01)\n",
    "# print()\n",
    "# DNN.learn(training_images, training_labels, 3, 0.01)\n",
    "# print()\n",
    "# HNN.learn(training_images, training_labels, 3, 0.01)\n",
    "# print()\n",
    "# GNN.learn(training_images, training_labels, 3, 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce9317b-d94c-4488-bbd8-b6ec313d6445",
   "metadata": {},
   "source": [
    "# Testing the Neural Network's General Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15cec46f-8671-4a63-b8bb-11b2a745fcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network's score: 92.60%\n"
     ]
    }
   ],
   "source": [
    "NN.test_set(test_images, test_labels)\n",
    "# DNN.test_set(test_images, test_labels)\n",
    "# HNN.test_set(test_images, test_labels)\n",
    "# GNN.test_set(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc9cb0c-b4a9-45bf-a6f3-122656a9a3d9",
   "metadata": {},
   "source": [
    "# Specific Example of the Neural Network Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40784d3e-589d-4c06-a713-987c8f601718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "guess: 8\n",
      "answer: 8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First, the middle 10, and last neuron output values in input layer:\n",
      "[0.] ... [0.] [0.] [0.] [0.] [0.] [0.19607843] [0.95686275] [0.9882353] [0.9882353] [0.99215686] ... [0.]\n",
      "\n",
      "First, the middle 10, and last neuron output values in hidden layer:\n",
      "[0.04168935] ... [0.99185067] [0.97466741] [0.96884732] [0.99940933] [0.00064648] [0.99633713] [0.0010098] [0.00385292] [0.00189183] [0.96056238] ... [0.99985675]\n",
      "\n",
      "All neuron output values in output layer:\n",
      "[9.6427344e-05] [0.00060677] [0.00137895] [0.00242906] [0.00114784] [0.00305927] [0.00149666] [2.75524869e-05] [0.99851454] [0.00541683]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = np.random.randint(len(test_images))\n",
    "image, label = test_images[index], test_labels[index]\n",
    "\n",
    "plt.imshow(image.reshape(28, 28), cmap='Greys')\n",
    "\n",
    "image.shape = (image.shape[0], 1)\n",
    "NN.test_single(image, label)\n",
    "plt.show()\n",
    "\n",
    "print('\\nFirst, the middle 10, and last neuron output values in input layer:')\n",
    "print(f'{NN.layers[0][0]} ... {NN.layers[0][398]} {NN.layers[0][399]} {NN.layers[0][400]} {NN.layers[0][401]} {NN.layers[0][402]} {NN.layers[0][403]} {NN.layers[0][404]} {NN.layers[0][405]} {NN.layers[0][406]} {NN.layers[0][407]} ... {NN.layers[0][783]}')\n",
    "print('\\nFirst, the middle 10, and last neuron output values in hidden layer:')\n",
    "print(f'{NN.layers[1][0]} ... {NN.layers[1][5]} {NN.layers[1][6]} {NN.layers[1][7]} {NN.layers[1][8]} {NN.layers[1][9]} {NN.layers[1][10]} {NN.layers[1][11]} {NN.layers[1][12]} {NN.layers[1][13]} {NN.layers[1][14]} ... {NN.layers[1][19]}')\n",
    "print('\\nAll neuron output values in output layer:')\n",
    "print(f'{NN.layers[2][0]} {NN.layers[2][1]} {NN.layers[2][2]} {NN.layers[2][3]} {NN.layers[2][4]} {NN.layers[2][5]} {NN.layers[2][6]} {NN.layers[2][7]} {NN.layers[2][8]} {NN.layers[2][9]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a2b976-fa44-4430-85f2-37834bbc5184",
   "metadata": {},
   "source": [
    "![alt text](images/example_model.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
